{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import align.detect_face\n",
    "\n",
    "\n",
    "\n",
    "# Keras\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.models import model_from_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opencv initialization\n",
    "\n",
    "# face_cascade = cv2.CascadeClassifier('/home/topica/anaconda3/envs/workspace/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# facenet \n",
    "image_size=160\n",
    "margin= 44\n",
    "gpu_memory_fraction=1.0\n",
    "\n",
    "def load_and_align_data(image_path, image_size,margin, gpu_memory_fraction):\n",
    "    minsize = 20 # minimum size of face\n",
    "    threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "    factor = 0.709 # scale factor\n",
    "    with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        with sess.as_default():\n",
    "            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n",
    "    img = scipy.misc.imread(os.path.expanduser(image_path))\n",
    "    img_size = np.asarray(img.shape)[0:2]\n",
    "    bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "    if (len(bounding_boxes)==0):\n",
    "        bb=0\n",
    "        have_face = 0\n",
    "    else:\n",
    "        det = np.squeeze(bounding_boxes[0,0:4])\n",
    "        bb = np.zeros(4, dtype=np.int32)\n",
    "        bb[0] = np.maximum(det[0]-margin/2, 0)\n",
    "        bb[1] = np.maximum(det[1]-margin/2, 0)\n",
    "        bb[2] = np.minimum(det[2]+margin/2 - bb[0], img_size[1])\n",
    "        bb[3] = np.minimum(det[3]+margin/2 - bb[1], img_size[0])\n",
    "        have_face = 1\n",
    "    return bb,have_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0925 18:06:52.095411 139660642678592 deprecation_wrapper.py:119] From /home/topica/anaconda3/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0925 18:06:52.121636 139660642678592 deprecation_wrapper.py:119] From /home/topica/anaconda3/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0925 18:06:52.124844 139660642678592 deprecation_wrapper.py:119] From /home/topica/anaconda3/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0925 18:06:52.163156 139660642678592 deprecation_wrapper.py:119] From /home/topica/anaconda3/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0925 18:06:52.163918 139660642678592 deprecation_wrapper.py:119] From /home/topica/anaconda3/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0925 18:06:52.230008 139660642678592 deprecation_wrapper.py:119] From /home/topica/anaconda3/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0925 18:06:52.293611 139660642678592 deprecation_wrapper.py:119] From /home/topica/anaconda3/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0925 18:06:52.301543 139660642678592 deprecation.py:506] From /home/topica/anaconda3/envs/py3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# model = model_from_json(open(\"/home/thaovu/tensorflow-101/model/facial_expression_model_structure.json\", \"r\").read())\n",
    "# model.load_weights('/home/thaovu/tensorflow-101/model/facial_expression_model_weights.h5') #load weights\n",
    "model = model_from_json(open(\"/home/topica/Emotion-web-API/models/model_4layer_2_2_pool.json\", \"r\").read())\n",
    "model.load_weights('/home/topica/Emotion-web-API/models/model_4layer_2_2_pool.h5') #load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/topica/Downloads/67644505_639817889862371_7193897395610976256_n.jpg'\n",
    "# # img = cv2.resize(img, (300, 400))\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 828, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/topica/anaconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(img_path)\n",
    "print(img.shape)\n",
    "detect_face, have_face= load_and_align_data(img_path,image_size,margin,gpu_memory_fraction)\n",
    "if (have_face!=0):\n",
    "    detect_face = np.reshape(detect_face,(-1,4)) \n",
    "    for (x,y,w,h) in detect_face:\n",
    "        detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "        detected_face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2GRAY) #transform to gray scale\n",
    "        detected_face = cv2.resize(detected_face, (48, 48)) #resize to 48x48\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(64,64,64),2) #highlight detected face\n",
    "        \n",
    "        img_pixels = image.img_to_array(detected_face)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\n",
    "        img_pixels /= 255 #pixels are in scale of [0, 255]. normalize all pixels in scale of [0, 1]\n",
    "\n",
    "        #-----------------------------\n",
    "\n",
    "        predictions = model.predict(img_pixels) #store probabilities of 7 expressions\n",
    "        max_index = np.argmax(predictions[0])\n",
    "        print(max_index)\n",
    "\n",
    "        #background of expression list\n",
    "        overlay = img.copy()\n",
    "        opacity = 0.4\n",
    "        cv2.rectangle(img,(x+w+15,y-25),(x+w+150,y+115),(64,64,64),cv2.FILLED)\n",
    "        cv2.addWeighted(overlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "        #connect face and expressions\n",
    "        cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),(255,255,255),1)\n",
    "        cv2.line(img,(x+w,y-20),(x+w+10,y-20),(255,255,255),1)\n",
    "\n",
    "        emotion = \"\"\n",
    "        for i in range(len(predictions[0])):\n",
    "            emotion = \"%s %s%s\" % (emotions[i], round(predictions[0][i]*100, 2), '%')\n",
    "\n",
    "            \"\"\"if i != max_index:\n",
    "                color = (255,0,0)\"\"\"\n",
    "\n",
    "            color = (255,0,0)\n",
    "\n",
    "            cv2.putText(img, emotion, (int(x+w+15), int(y-12+i*20)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "cv2.imwrite('thao_fear.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 828, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/topica/anaconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(img_path)\n",
    "print(img.shape)\n",
    "detect_face, have_face= load_and_align_data(img_path,image_size,margin,gpu_memory_fraction)\n",
    "if (have_face!=0):\n",
    "    detect_face = np.reshape(detect_face,(-1,4)) \n",
    "    result = []\n",
    "    for (x,y,w,h) in detect_face:\n",
    "        detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "        detected_face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2GRAY) #transform to gray scale\n",
    "        detected_face = cv2.resize(detected_face, (48, 48)) #resize to 48x48\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(64,64,64),2) #highlight detected face\n",
    "        \n",
    "        img_pixels = image.img_to_array(detected_face)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\n",
    "        img_pixels /= 255 #pixels are in scale of [0, 255]. normalize all pixels in scale of [0, 1]\n",
    "\n",
    "        #-----------------------------\n",
    "\n",
    "        predictions = model.predict(img_pixels) #store probabilities of 7 expressions\n",
    "        max_index = np.argmax(predictions[0])\n",
    "        print(max_index)\n",
    "        \n",
    "        face = {}\n",
    "        face ['position'] = [x,y,w,h]\n",
    "        a = []\n",
    "        for i in range(len(predictions[0])):\n",
    "            a.append({'emotions': emotions[i], 'prob':round(predictions[0][i]*100, 2), })\n",
    "        face['emotion'] = a\n",
    "        result.append(face)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'position': [279, 48, 162, 205],\n",
       "  'emotion': [{'emotions': 'angry', 'prob': 99.47},\n",
       "   {'emotions': 'disgust', 'prob': 0.0},\n",
       "   {'emotions': 'fear', 'prob': 0.0},\n",
       "   {'emotions': 'happy', 'prob': 0.0},\n",
       "   {'emotions': 'sad', 'prob': 0.07},\n",
       "   {'emotions': 'surprise', 'prob': 0.0},\n",
       "   {'emotions': 'neutral', 'prob': 0.84}]}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b4c85eba1448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#if w > 130: #trick: ignore small faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m#cv2.rectangle(img,(x,y),(x+w,y+h),(64,64,64),2) #highlight detected face\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'faces' is not defined"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for (x,y,w,h) in faces:\n",
    "    #if w > 130: #trick: ignore small faces\n",
    "        #cv2.rectangle(img,(x,y),(x+w,y+h),(64,64,64),2) #highlight detected face\n",
    "\n",
    "        detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "        detected_face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2GRAY) #transform to gray scale\n",
    "        detected_face = cv2.resize(detected_face, (48, 48)) #resize to 48x48\n",
    "\n",
    "        img_pixels = image.img_to_array(detected_face)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\n",
    "        img_pixels /= 255 #pixels are in scale of [0, 255]. normalize all pixels in scale of [0, 1]\n",
    "\n",
    "        #------------------------------\n",
    "        predictions = model.predict(img_pixels) #store probabilities of 7 expressions\n",
    "        preds.append(predictions)\n",
    "        print(len(preds[0]))\n",
    "        print (predictions)\n",
    "        max_index = np.argmax(predictions[0])\n",
    "        print(max_index)\n",
    "\n",
    "        #background of expression list\n",
    "        overlay = img.copy()\n",
    "        opacity = 0.4\n",
    "        cv2.rectangle(img,(x+w+15,y-25),(x+w+150,y+115),(64,64,64),cv2.FILLED)\n",
    "        cv2.addWeighted(overlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "        #connect face and expressions\n",
    "        cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),(255,255,255),1)\n",
    "        cv2.line(img,(x+w,y-20),(x+w+10,y-20),(255,255,255),1)\n",
    "\n",
    "        emotion = \"\"\n",
    "        for i in range(len(predictions[0])):\n",
    "            emotion = \"%s %s%s\" % (emotions[i], round(predictions[0][i]*100, 2), '%')\n",
    "\n",
    "            \"\"\"if i != max_index:\n",
    "                color = (255,0,0)\"\"\"\n",
    "\n",
    "            color = (255,0,0)\n",
    "\n",
    "            cv2.putText(img, emotion, (int(x+w+15), int(y-12+i*20)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "cv2.imwrite('c15.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
