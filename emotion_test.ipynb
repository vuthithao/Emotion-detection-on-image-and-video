{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing import image\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "import align.detect_face\n",
    "\n",
    "\n",
    "\n",
    "# Keras\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.models import model_from_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opencv initialization\n",
    "\n",
    "# face_cascade = cv2.CascadeClassifier('/home/topica/anaconda3/envs/workspace/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# facenet \n",
    "image_size=160\n",
    "margin= 44\n",
    "gpu_memory_fraction=1.0\n",
    "\n",
    "def load_and_align_data(image_path, image_size,margin, gpu_memory_fraction):\n",
    "    minsize = 20 # minimum size of face\n",
    "    threshold = [ 0.6, 0.7, 0.7 ]  # three steps's threshold\n",
    "    factor = 0.709 # scale factor\n",
    "    with tf.Graph().as_default():\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n",
    "        with sess.as_default():\n",
    "            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n",
    "    img = scipy.misc.imread(os.path.expanduser(image_path))\n",
    "    img_size = np.asarray(img.shape)[0:2]\n",
    "    bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n",
    "    if (len(bounding_boxes)==0):\n",
    "        bb=0\n",
    "        have_face = 0\n",
    "    else:\n",
    "        det = np.squeeze(bounding_boxes[0,0:4])\n",
    "        bb = np.zeros(4, dtype=np.int32)\n",
    "        bb[0] = np.maximum(det[0]-margin/2, 0)\n",
    "        bb[1] = np.maximum(det[1]-margin/2, 0)\n",
    "        bb[2] = np.minimum(det[2]+margin/2 - bb[0], img_size[1])\n",
    "        bb[3] = np.minimum(det[3]+margin/2 - bb[1], img_size[0])\n",
    "        have_face = 1\n",
    "    return bb,have_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# model = model_from_json(open(\"/home/thaovu/tensorflow-101/model/facial_expression_model_structure.json\", \"r\").read())\n",
    "# model.load_weights('/home/thaovu/tensorflow-101/model/facial_expression_model_weights.h5') #load weights\n",
    "model = model_from_json(open(\"/home/topica/workspace/Facial-Expression-Recognition/model_4layer_2_2_pool.json\", \"r\").read())\n",
    "model.load_weights('/home/topica/workspace/Facial-Expression-Recognition/model_4layer_2_2_pool.h5') #load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/topica/Pictures/Webcam/fear9.jpg'\n",
    "# # img = cv2.resize(img, (300, 400))\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/topica/anaconda3/envs/workspace/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(img_path)\n",
    "detect_face, have_face= load_and_align_data(img_path,image_size,margin,gpu_memory_fraction)\n",
    "if (have_face!=0):\n",
    "    detect_face = np.reshape(detect_face,(-1,4)) \n",
    "    for (x,y,w,h) in detect_face:\n",
    "        detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "        detected_face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2GRAY) #transform to gray scale\n",
    "        detected_face = cv2.resize(detected_face, (48, 48)) #resize to 48x48\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(64,64,64),2) #highlight detected face\n",
    "        \n",
    "        img_pixels = image.img_to_array(detected_face)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\n",
    "        img_pixels /= 255 #pixels are in scale of [0, 255]. normalize all pixels in scale of [0, 1]\n",
    "\n",
    "        #-----------------------------\n",
    "\n",
    "        predictions = model.predict(img_pixels) #store probabilities of 7 expressions\n",
    "        max_index = np.argmax(predictions[0])\n",
    "        print(max_index)\n",
    "\n",
    "        #background of expression list\n",
    "        overlay = img.copy()\n",
    "        opacity = 0.4\n",
    "        cv2.rectangle(img,(x+w+15,y-25),(x+w+150,y+115),(64,64,64),cv2.FILLED)\n",
    "        cv2.addWeighted(overlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "        #connect face and expressions\n",
    "        cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),(255,255,255),1)\n",
    "        cv2.line(img,(x+w,y-20),(x+w+10,y-20),(255,255,255),1)\n",
    "\n",
    "        emotion = \"\"\n",
    "        for i in range(len(predictions[0])):\n",
    "            emotion = \"%s %s%s\" % (emotions[i], round(predictions[0][i]*100, 2), '%')\n",
    "\n",
    "            \"\"\"if i != max_index:\n",
    "                color = (255,0,0)\"\"\"\n",
    "\n",
    "            color = (255,0,0)\n",
    "\n",
    "            cv2.putText(img, emotion, (int(x+w+15), int(y-12+i*20)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "cv2.imwrite('thao_fear.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for (x,y,w,h) in faces:\n",
    "    #if w > 130: #trick: ignore small faces\n",
    "        #cv2.rectangle(img,(x,y),(x+w,y+h),(64,64,64),2) #highlight detected face\n",
    "\n",
    "        detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "        detected_face = cv2.cvtColor(detected_face, cv2.COLOR_BGR2GRAY) #transform to gray scale\n",
    "        detected_face = cv2.resize(detected_face, (48, 48)) #resize to 48x48\n",
    "\n",
    "        img_pixels = image.img_to_array(detected_face)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\n",
    "        img_pixels /= 255 #pixels are in scale of [0, 255]. normalize all pixels in scale of [0, 1]\n",
    "\n",
    "        #------------------------------\n",
    "        predictions = model.predict(img_pixels) #store probabilities of 7 expressions\n",
    "        preds.append(predictions)\n",
    "        print(len(preds[0]))\n",
    "        print (predictions)\n",
    "        max_index = np.argmax(predictions[0])\n",
    "        print(max_index)\n",
    "\n",
    "        #background of expression list\n",
    "        overlay = img.copy()\n",
    "        opacity = 0.4\n",
    "        cv2.rectangle(img,(x+w+15,y-25),(x+w+150,y+115),(64,64,64),cv2.FILLED)\n",
    "        cv2.addWeighted(overlay, opacity, img, 1 - opacity, 0, img)\n",
    "\n",
    "        #connect face and expressions\n",
    "        cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),(255,255,255),1)\n",
    "        cv2.line(img,(x+w,y-20),(x+w+10,y-20),(255,255,255),1)\n",
    "\n",
    "        emotion = \"\"\n",
    "        for i in range(len(predictions[0])):\n",
    "            emotion = \"%s %s%s\" % (emotions[i], round(predictions[0][i]*100, 2), '%')\n",
    "\n",
    "            \"\"\"if i != max_index:\n",
    "                color = (255,0,0)\"\"\"\n",
    "\n",
    "            color = (255,0,0)\n",
    "\n",
    "            cv2.putText(img, emotion, (int(x+w+15), int(y-12+i*20)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "cv2.imwrite('c15.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
